# Stage , Use an official Python runtime as the first base image
FROM python:3.9-slim AS python-base

# Install Java, Git, and other dependencies
RUN apt-get update && apt-get install -y \
    git \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Install Jupyter Notebook
RUN pip install jupyter

# Stage 2: Use the second base image
FROM openjdk:11-slim AS java-base

# Install Java, Git, and other dependencies
RUN apt-get update && apt-get install -y \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Install Spark
RUN wget https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz && \
    tar -xvzf spark-3.1.2-bin-hadoop3.2.tgz && \
    mv spark-3.1.2-bin-hadoop3.2 /usr/local/spark && \
    rm spark-3.1.2-bin-hadoop3.2.tgz

# Set environment variables for Spark
ENV SPARK_HOME=/usr/local/spark
ENV PATH=$SPARK_HOME/bin:$PATH

# Stage 3: Combine the results
FROM python-base AS final

# Copy files from the java-base stage
COPY --from=java-base /usr/local/spark /usr/local/spark

# Set the working directory in the container
WORKDIR /GIT

# Install PyTorch, PySpark, SparkTorch
RUN pip install torch pyspark sparktorch 

# Expose any necessary ports
EXPOSE 8080

