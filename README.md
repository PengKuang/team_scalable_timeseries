# Time series anomaly detection using Autoencoders
> Authors: [Kasper Bågmark](https://research.chalmers.se/person/bagmark) (Chalmers University), [Michele Di Sabato](https://www.umu.se/en/staff/michele-di-sabato/) (Umeå University), [Erik Jansson](https://www.chalmers.se/en/persons/erikjans/) (Chalmers University), [Peng Kuang](https://portal.research.lu.se/en/persons/peng-kuang) (Lund University) and [Selma Tabakovic](https://www.chalmers.se/en/persons/selmat/) (Chalmers University)
* **Project title**: Time series anomaly detection using Autoencoders
* **Description**: This project addresses scalable anomaly detection in time series data, focusing on electrocardiograms (ECGs). The goal is to identify anomalous heartbeats that deviate from normal patterns using autoencoders—a type of neural network that compresses data into a latent representation and reconstructs it. Poor reconstruction of anomalous signals, compared to normal ones, forms the basis for anomaly detection. Unlike traditional time-series models, this approach is fully data-driven, avoiding explicit modeling of time-series dynamics. A distributed ensemble method ensures scalability for large datasets, using PySpark and TorchDistributor to train models across multiple nodes. This setup supports privacy preservation by localizing data at healthcare institutions and synchronizing model updates centrally. The experiment setup consists of partitioning data and distributing training across CPU cores on a single ECG data set. Reconstruction loss distributions allow for threshold-based classification of anomalies. Preliminary results demonstrate efficient hardware utilization and reliable anomaly detection, though challenges remain in handling unseen anomaly types and node imbalance. This work demonstrates the potential of distributed deep learning for large-scale medical anomaly detection, highlighting privacy preservation, scalability, and effective resource usage.
* **Links**: The file [report.md](report.md) has been used during the presentation. Please refer to the file [docker.md](docker.md) for instructions on how to use docker to run this project (although not necessary). The file [model_pipeline.ipynb](model_pipeline.ipynb) contains the main code for this project. 
* **Author's contribution**:
    - Kasper Bågmark: Responsibility for the ensemble idea and creating a scalable setup with TorchDistributor. Investigated different options for scalability.
    - Michele Di Sabato: Provided the initial idea of analysis, dataset management and main responsibility of the final code.
    - Erik Jansson: Did a thorough literature review of relevant methods for using autoencoders on timeseries. Provided the finalized project idea and created the figures in the report.
    - Peng Kuang: Investigated scalability, especially for federated learning in general. Provided the docker image and made sure that the collaboration worked smoothly.
    - Selma Tabakovic: Most of the initial investigation of using autoencoders on different datasets and different evaluations of this. Main responsibility of the final data that we used.
    - Everyone: Experimented with setup, autoencoders and timeseries analysis in different ways before the final project was finalized. 
